# app.py

import streamlit as st
import pandas as pd
import numpy as np
import itertools
import plotly.graph_objects as go
import plotly.express as px

from arch import arch_model
from scipy.stats import genpareto
from hmmlearn.hmm import GaussianHMM
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) UTILITY & CALIBRATION FUNCTIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SQRT252 = np.sqrt(252)
MANUAL_BANDS = {
    'Low':       (0.00, 0.07),
    'Medium':    (0.07, 0.50),
    'High':      (0.50, 0.60),
    'VeryHigh':  (0.60, None)
}

def compute_manual_groups(df):
    df2 = df.copy()
    df2['DailyVol'] = df2['OHLCVolatility'] / SQRT252
    mean_vol = (
        df2.groupby('Currency')['DailyVol']
           .mean()
           .reset_index(name='MeanDailyVol')
    )
    def assign_band(v):
        for b,(lo,hi) in MANUAL_BANDS.items():
            if hi is None and v >= lo: return b
            if lo <= v < hi:           return b
        return None
    mean_vol['Band'] = mean_vol['MeanDailyVol'].map(assign_band)
    band_thr = (
        mean_vol.groupby('Band')['MeanDailyVol']
                .max()
                .reset_index(name='BandThreshold')
    )
    return mean_vol, band_thr

def build_crosses(df):
    piv_c = df.pivot(index='Date', columns='Currency', values='Close')
    piv_v = df.pivot(index='Date', columns='Currency', values='DailyVol')  # DAILY VOL
    crosses = []
    codes = sorted(df['Currency'].unique())
    for i, base in enumerate(codes):
        for quote in codes[i+1:]:
            rate = piv_c[quote] / piv_c[base]
            vol  = np.sqrt(piv_v[base]**2 + piv_v[quote]**2)
            lr   = np.log(rate / rate.shift(1))
            tmp = pd.DataFrame({
                'Date':       rate.index,
                'Cross':      f"{base}/{quote}",
                'Volatility': vol.values,
                'LogReturn':  lr.values
            }).dropna()
            crosses.append(tmp)
    return pd.concat(crosses, ignore_index=True)

def rolling_quantile(vol, window, q):
    return vol.rolling(window).quantile(q)

def garch_evt(returns, tail_pct):
    am = arch_model(returns * 100, vol='Garch', p=1, q=1)
    res = am.fit(disp='off')
    std = res.resid / res.conditional_volatility
    std = std[~np.isnan(std)]
    u = np.quantile(std, 0.90)
    exceed = std[std > u] - u
    c, loc, scale = genpareto.fit(exceed, floc=0)
    p_exc = (tail_pct - (1 - np.mean(std > u))) / np.mean(std > u)
    var = genpareto.ppf(p_exc, c, loc=0, scale=scale)
    return (u + var) / 100.0

def detect_regimes(vol, n_states):
    model = GaussianHMM(n_components=n_states, covariance_type='full', n_iter=100)
    arr = vol.values.reshape(-1,1)
    model.fit(arr)
    states = model.predict(arr)
    means = {s: arr[states==s].mean() for s in np.unique(states)}
    high = max(means, key=means.get)
    return states, high, means[high]

def calibrate_regime(vol, lr, target_rate, windows, qs, tails):
    # Rolling calibration
    best_roll = min(
        ((abs((vol > rolling_quantile(vol,w,q)).mean() - target_rate),(w,q))
         for w,q in itertools.product(windows,qs)),
        key=lambda x: x[0]
    )[1]
    # EVT calibration
    best_evt = min(
        ((abs((vol > garch_evt(lr,tail)).mean() - target_rate), tail)
         for tail in tails),
        key=lambda x: x[0]
    )[1]
    return {'window': best_roll[0], 'quantile': best_roll[1], 'tail': best_evt}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) STREAMLIT UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="FX Threshold PoC", layout="wide")
st.title("Regime-Aware, Multi-Tier FX Volatility Thresholding")

# Sidebar: Upload & Base Settings
st.sidebar.header("1ï¸âƒ£ Upload Data")
f = st.sidebar.file_uploader(
    "Upload CSV (Date,Open,High,Low,Close,OHLCVolatility,Currency)",
    type="csv"
)
if not f:
    st.sidebar.info("Please upload your FX data.")
    st.stop()

df = pd.read_csv(f, parse_dates=['Date']).sort_values('Date')
# Convert to daily vol
df['DailyVol'] = df['OHLCVolatility'] / SQRT252

# Manual groups
mean_vol_df, band_thr_df = compute_manual_groups(df)

# Build crosses
cross_df = build_crosses(df)
cross_list = sorted(cross_df['Cross'].unique())
sel_cross  = st.sidebar.selectbox("Select Cross", cross_list)

# HMM regimes
st.sidebar.header("2ï¸âƒ£ Regime Detection")
n_states = st.sidebar.slider("HMM States", 2, 4, 2)

# Calibration settings
st.sidebar.header("3ï¸âƒ£ Calibration Targets")
target_rate = st.sidebar.slider("Target Alert Rate", 0.01, 0.20, 0.05, 0.01)
roll_windows = [30, 60, 90, 120]
roll_qs      = [0.90, 0.95, 0.99]
evt_tails    = [0.990, 0.995, 0.999]

# Multi-tier selection
st.sidebar.header("4ï¸âƒ£ Multi-Tier Alerts")
tiers = st.sidebar.multiselect(
    "Show tiers", ['Warning (90%)','Alert (95%)','Critical (EVT)'],
    default=['Alert (95%)']
)

# Consensus fraction
st.sidebar.header("5ï¸âƒ£ Consensus")
consensus_frac = st.sidebar.slider("Consensus Fraction", 0.1, 1.0, 0.5, 0.05)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Filter & compute for selected cross
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dfc = cross_df.query("Cross == @sel_cross").reset_index(drop=True)

# Manual threshold
base,quote = sel_cross.split('/')
b1 = mean_vol_df.loc[mean_vol_df.Currency==base,'Band'].iat[0]
b2 = mean_vol_df.loc[mean_vol_df.Currency==quote,'Band'].iat[0]
order = ['Low','Medium','High','VeryHigh']
man_band = b1 if order.index(b1) > order.index(b2) else b2
man_thr  = band_thr_df.loc[band_thr_df.Band==man_band,'BandThreshold'].iat[0]

# HMM regimes & threshold
dfc['Regime'], high_regime, hmm_thr = detect_regimes(dfc['Volatility'], n_states)
reg_labels = {s:f"Regime {s}" for s in sorted(dfc['Regime'].unique())}

# Per-regime calibration
calib = {}
for s, grp in dfc.groupby('Regime'):
    cp = calibrate_regime(
        grp['Volatility'], grp['LogReturn'], target_rate,
        roll_windows, roll_qs, evt_tails
    )
    calib[s] = cp

# Compute tier thresholds per row
dfc['Thr_Warning'] = dfc.apply(
    lambda r: rolling_quantile(
        dfc.loc[dfc.Regime==r.Regime,'Volatility'],
        calib[r.Regime]['window'],
        0.90
    ).iloc[r.name],
    axis=1
)
dfc['Thr_Alert'] = dfc.apply(
    lambda r: rolling_quantile(
        dfc.loc[dfc.Regime==r.Regime,'Volatility'],
        calib[r.Regime]['window'],
        calib[r.Regime]['quantile']
    ).iloc[r.name],
    axis=1
)
dfc['Thr_Critical'] = dfc['Regime'].map({
    s: garch_evt(
        dfc.loc[dfc.Regime==s,'LogReturn'].values,
        calib[s]['tail']
    ) for s in calib
})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tabs: Overview, Regimes & Calibration, Dashboard
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3 = st.tabs([
    "ðŸ“‹ Overview",
    "ðŸ”§ Regimes & Calibration",
    "ðŸ“Š Dashboard"
])

with tab1:
    st.header("Businessâ€Driven FX Vol Thresholding")
    st.markdown("""
    **1) Define a Target Alert Rate**  
    Align falseâ€alarm vs. missedâ€alarm costs with stakeholders.

    **2) Detect Regimes**  
    Use HMM to split data into Calm/Normal/Stress states.

    **3) Perâ€Regime Calibration**  
    Find rolling-window & quantile + EVT tail that deliver the target rate.

    **4) Multiâ€Tier Alerts**  
    - Warning:  90thâ€percentile  
    - Alert:    95thâ€percentile  
    - Critical: EVT tailâ€risk  

    **5) Consensus**  
    Require a fraction of signals (Rolling & EVT) to agree, reducing noise.

    **This framework** is fully **defensible**, **dataâ€driven**, and **explainable**.
    """)

with tab2:
    st.header("Regimes & Calibrated Parameters")

    # Regime timeline
    dfc['RegimeLabel'] = dfc['Regime'].map(reg_labels)
    fig_r = px.scatter(
        dfc, x='Date', y='Volatility', color='RegimeLabel',
        title="Volatility Colored by HMM Regime"
    )
    st.plotly_chart(fig_r, use_container_width=True)

    # Calibration table
    cal_rows = []
    for s,cp in calib.items():
        cal_rows.append({
            'Regime': reg_labels[s],
            'RollWin': cp['window'],
            'RollQ':   cp['quantile'],
            'EVT Tail':cp['tail']
        })
    st.table(pd.DataFrame(cal_rows))

with tab3:
    st.header(f"Dashboard â€” Cross: {sel_cross}")

    latest = dfc.iloc[-1]
    # KPI cards: include Manual Thr first
    cols = st.columns(6)
    cols[0].metric("Manual Thr",         f"{man_thr:.4f}")
    cols[1].metric("Latest Vol",         f"{latest.Volatility:.4f}")
    cols[2].metric("Warning Thr (90%)",  f"{latest.Thr_Warning:.4f}")
    cols[3].metric("Alert Thr (95%)",    f"{latest.Thr_Alert:.4f}")
    cols[4].metric("Critical Thr (EVT)", f"{latest.Thr_Critical:.4f}")
    cols[5].metric("Regime",             f"{reg_labels[latest.Regime]}")

    st.markdown("---")
    # Overlay thresholds
    fig_d = go.Figure()
    fig_d.add_trace(go.Scatter(
        x=dfc.Date, y=dfc.Volatility, name='Volatility', line=dict(color='blue')
    ))
    if 'Warning (90%)' in tiers:
        fig_d.add_trace(go.Scatter(
            x=dfc.Date, y=dfc.Thr_Warning,
            name='Warning', line=dict(dash='dash',color='orange')
        ))
    if 'Alert (95%)' in tiers:
        fig_d.add_trace(go.Scatter(
            x=dfc.Date, y=dfc.Thr_Alert,
            name='Alert', line=dict(dash='dot',color='red')
        ))
    if 'Critical (EVT)' in tiers:
        fig_d.add_trace(go.Scatter(
            x=dfc.Date, y=dfc.Thr_Critical,
            name='Critical', line=dict(dash='longdash',color='black')
        ))
    fig_d.update_layout(
        xaxis=dict(rangeslider=dict(visible=True)),
        height=450,
        yaxis_title="Daily Volatility"
    )
    st.plotly_chart(fig_d, use_container_width=True)

    st.markdown("---")
    # Breachâ€rate bar
    breach_rates = {
        'Warning': (dfc.Volatility>dfc.Thr_Warning).mean(),
        'Alert':   (dfc.Volatility>dfc.Thr_Alert).mean(),
        'Critical':(dfc.Volatility>dfc.Thr_Critical).mean()
    }
    st.bar_chart(pd.Series(breach_rates, name='Breach Rate'))

    st.markdown("**Consensus (Rolling & EVT)**: "
                f"{( (dfc.Volatility>dfc.Thr_Alert).astype(int) + (dfc.Volatility>dfc.Thr_Critical).astype(int) )/2.0 >= consensus_frac.mean():.1%}")
