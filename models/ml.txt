import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

def run_isolation_forest(X, contamination=0.05, random_state=42):
    """
    1 = anomaly, 0 = normal.
    Business note: tree‐based anomalies complement threshold rules.
    """
    clf   = IsolationForest(contamination=contamination, random_state=random_state)
    preds = clf.fit_predict(X)    #  1=inlier, -1=outlier
    return np.where(preds == -1, 1, 0)

def run_one_class_svm(X, nu=0.05, kernel='rbf', gamma='scale'):
    """
    1 = anomaly, 0 = normal.
    Business note: boundary method to catch subtle regime shifts.
    """
    clf   = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)
    preds = clf.fit_predict(X)    #  1=inlier, -1=outlier
    return np.where(preds == -1, 1, 0)

def run_autoencoder(
    X,
    encoding_dim: int = 10,
    epochs: int = 50,
    batch_size: int = 32,
    learning_rate: float = 0.001
):
    """
    Return per-row MSE reconstruction errors.
    Business note: captures complex non‐linear patterns.
    """
    scaler    = StandardScaler()
    X_scaled  = scaler.fit_transform(X)
    n_feats   = X_scaled.shape[1]

    model = Sequential([
        Dense(encoding_dim*2, activation='relu', input_shape=(n_feats,)),
        Dense(encoding_dim,   activation='relu'),
        Dense(encoding_dim*2, activation='relu'),
        Dense(n_feats,        activation='linear')
    ])
    model.compile(optimizer=Adam(learning_rate), loss='mse')
    model.fit(X_scaled, X_scaled, epochs=epochs, batch_size=batch_size, verbose=0)

    recon = model.predict(X_scaled)
    mse   = np.mean((X_scaled - recon)**2, axis=1)
    return mse
