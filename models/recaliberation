# app.py

import streamlit as st
import pandas as pd
import numpy as np
import itertools, datetime
import plotly.graph_objects as go
import plotly.express as px

from arch import arch_model
from scipy.stats import genpareto
from hmmlearn.hmm import GaussianHMM

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UTILS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SQRT252 = np.sqrt(252)
MANUAL_BANDS = {
    'Low':      (0.00, 0.07),
    'Medium':   (0.07, 0.50),
    'High':     (0.50, 0.60),
    'VeryHigh': (0.60, None)
}

def compute_manual_groups(df):
    df2 = df.copy(); df2['DailyVol'] = df2['OHLCVolatility']/SQRT252
    mv = df2.groupby('Currency')['DailyVol'].mean().reset_index(name='MeanDailyVol')
    def band(v):
        for b,(lo,hi) in MANUAL_BANDS.items():
            if hi is None and v>=lo: return b
            if lo<=v<hi:            return b
        return None
    mv['Band'] = mv['MeanDailyVol'].map(band)
    bt = mv.groupby('Band')['MeanDailyVol'].max().reset_index(name='BandThreshold')
    return mv, bt

def rolling_quantile(vol, w, q): return vol.rolling(w).quantile(q)

def garch_evt(returns, tail_pct):
    am  = arch_model(returns*100, vol='Garch', p=1, q=1)
    res = am.fit(disp='off')
    std = res.resid/res.conditional_volatility
    std = std[np.isfinite(std)]
    u   = np.quantile(std,0.90)
    exc = std[std>u]-u
    c,l,s = genpareto.fit(exc,floc=0)
    p_exc = (tail_pct - (1-np.mean(std>u)))/np.mean(std>u)
    var   = genpareto.ppf(p_exc,c,loc=0,scale=s)
    return (u+var)/100.0

def detect_regimes(vol, n_states):
    clean = vol.replace([np.inf,-np.inf],np.nan).dropna()
    if clean.empty:
        return np.zeros(len(vol),int), 0, np.nan
    arr = clean.values.reshape(-1,1)
    model = GaussianHMM(n_components=n_states,
                        covariance_type='full', n_iter=200)
    model.fit(arr)
    raw = model.predict(arr)
    means = {s: arr[raw==s].mean() for s in np.unique(raw)}
    high  = max(means, key=means.get)
    s = pd.Series(raw, index=clean.index)
    full = s.reindex(vol.index).ffill().bfill().astype(int)
    return full.values, high, means[high]

def smooth_regimes(raw, min_run=5):
    s = pd.Series(raw)
    runs    = (s!=s.shift()).cumsum()
    lengths = s.groupby(runs).transform('size')
    s[lengths<min_run] = np.nan
    return s.ffill().bfill().astype(int).values

def calibrate_regime(vol, lr, target, windows, qs, tails):
    best_wq = min(
      ((abs((vol>rolling_quantile(vol,w,q)).mean()-target),(w,q))
       for w,q in itertools.product(windows,qs)),
      key=lambda x:x[0])[1]
    best_t = min(
      ((abs((vol>garch_evt(lr,t)).mean()-target),t)
       for t in tails),
      key=lambda x:x[0])[1]
    return {'window':best_wq[0],'quantile':best_wq[1],'tail':best_t}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# APP START
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(page_title="FX Threshold & Regimes", layout="wide")
st.title("ðŸ“Š FX Volatility: Threshold & Regimeâ€Shift Dashboard")

# Sidebar
st.sidebar.header("1ï¸âƒ£ Upload FX Data")
f = st.sidebar.file_uploader("CSV: Date,Open,High,Low,Close,OHLCVolatility,Currency", type="csv")
if not f:
    st.sidebar.info("Upload your FX dataset to begin.")
    st.stop()

df = pd.read_csv(f, parse_dates=['Date']).sort_values(['Currency','Date'])
df['DailyVol'] = df['OHLCVolatility']/SQRT252

mean_vol_df, band_thr_df = compute_manual_groups(df)

# Cross list
cross_df = df.pivot(index='Date', columns='Currency', values='DailyVol')
crosses  = sorted([f"{b}/{q}" for i,b in enumerate(cross_df.columns)
                   for q in cross_df.columns[i+1:]])
sel_cross = st.sidebar.selectbox("2ï¸âƒ£ Select FX Cross", crosses)
base_cc, quote_cc = sel_cross.split('/')

# Regime & calibration controls
n_states    = st.sidebar.slider("3ï¸âƒ£ HMM States", 2, 4, 2)
st.sidebar.header("4ï¸âƒ£ Calibration Targets")
target_rate = st.sidebar.slider("Target Alert Rate", 0.01,0.20,0.05,0.01)
roll_windows= [30,60,90,120]; roll_qs=[0.90,0.95,0.99]; evt_tails=[0.990,0.995,0.999]
st.sidebar.header("5ï¸âƒ£ Multiâ€Tier & Consensus")
tiers      = st.sidebar.multiselect("Show Tiers",
              ['Warning (90%)','Alert (95%)','Critical (EVT)'],
              default=['Alert (95%)'])
cons_frac  = st.sidebar.slider("Consensus Fraction", 0.1,1.0,0.5,0.05)

# Prepare series
base_ser  = df[df.Currency==base_cc].set_index('Date')['DailyVol']
quote_ser = df[df.Currency==quote_cc].set_index('Date')['DailyVol']
common    = base_ser.index.intersection(quote_ser.index)
cross_vol = np.sqrt(base_ser.loc[common]**2 + quote_ser.loc[common]**2)
cross_lr  = np.log(
    df[df.Currency==quote_cc].set_index('Date')['Close'].loc[common] /
    df[df.Currency==base_cc].set_index('Date')['Close'].loc[common]
)

# HMM + smoothing
raw_b,high_b,thr_b = detect_regimes(base_ser, n_states)
raw_q,high_q,thr_q = detect_regimes(quote_ser,n_states)
raw_x,high_x,thr_x = detect_regimes(cross_vol,n_states)

states_b = smooth_regimes(raw_b,5)
states_q = smooth_regimes(raw_q,5)
states_x = smooth_regimes(raw_x,5)

# DataFrames
df_base  = pd.DataFrame({'Date':base_ser.index,  'Vol':base_ser.values,  'Regime':states_b})
df_quote = pd.DataFrame({'Date':quote_ser.index,'Vol':quote_ser.values,'Regime':states_q})
df_cross = pd.DataFrame({'Date':common,        'Vol':cross_vol.values,'Regime':states_x})
for ddf in (df_base,df_quote,df_cross):
    ddf['RegLabel']=ddf.Regime.map(lambda s:f"Regime {s}")
chg_b = df_base.Regime.ne(df_base.Regime.shift())
chg_q = df_quote.Regime.ne(df_quote.Regime.shift())
chg_x = df_cross.Regime.ne(df_cross.Regime.shift())

# Threshold prep
dfc = df_cross.copy().set_index('Date')
mv = mean_vol_df.set_index('Currency')['MeanDailyVol']
mb1,mb2 = mean_vol_df.set_index('Currency')['Band'][[base_cc,quote_cc]]
order   = ['Low','Medium','High','VeryHigh']
man_band= mb1 if order.index(mb1)>order.index(mb2) else mb2
man_thr = band_thr_df.set_index('Band')['BandThreshold'][man_band]

# Per-regime calibrate & tier thresholds
calib = {
    r: calibrate_regime(
          grp['Vol'],
          np.log(grp['Vol']/grp['Vol'].shift(1)).dropna(),
          target_rate, roll_windows, roll_qs, evt_tails
       )
    for r,grp in df_cross.groupby('Regime')
}
dfc['Thr_Warning']=np.nan; dfc['Thr_Alert']=np.nan
for r,grp in dfc.groupby('Regime'):
    w,q=calib[r]['window'],calib[r]['quantile']
    dfc.loc[grp.index,'Thr_Warning']=rolling_quantile(grp['Vol'],w,0.90)
    dfc.loc[grp.index,'Thr_Alert']  =rolling_quantile(grp['Vol'],w,q)
dfc['Thr_Critical'] = dfc.Regime.map(
    lambda r: garch_evt(cross_lr.values, calib[r]['tail'])
)
cons_series = (((dfc['Vol']>dfc['Thr_Alert']).astype(int)+
                (dfc['Vol']>dfc['Thr_Critical']).astype(int))/2
               >= cons_frac)
cons_rate   = cons_series.mean()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TABS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tabs = st.tabs([
    "ðŸ“‹ Overview",
    "ðŸ”¢ Threshold Dashboard",
    f"âš™ï¸ {base_cc} Regimes",
    f"âš™ï¸ {quote_cc} Regimes",
    f"âš™ï¸ {base_cc}/{quote_cc} Regimes",
    "ðŸš€ Shock Simulation"
])

# Overview
with tabs[0]:
    st.header("Why This Framework?")
    st.markdown("""
    - **Target Alert Rate** â€“ align alerts to cost tradeâ€offs.  
    - **HMM Regimes** â€“ autoâ€detect calm/normal/stress states.  
    - **Perâ€Regime Calibration** â€“ rolling & EVT per state.  
    - **Multiâ€Tier Alerts** â€“ 90th/95th/EVT.  
    - **Consensus** â€“ combine signals for robustness.
    """)

# Threshold Dashboard
with tabs[1]:
    st.header(f"ðŸ”¢ Threshold Dashboard â€” {sel_cross}")
    c0,c1,c2,c3,c4,c5 = st.columns(6)
    c0.metric("Manual Thr",     f"{man_thr:.4f}")
    c1.metric("Latest Vol",     f"{dfc['Vol'].iat[-1]:.4f}")
    c2.metric("Warning Thr",    f"{dfc['Thr_Warning'].iat[-1]:.4f}")
    c3.metric("Alert Thr",      f"{dfc['Thr_Alert'].iat[-1]:.4f}")
    c4.metric("Critical Thr",   f"{dfc['Thr_Critical'].iat[-1]:.4f}")
    c5.metric("Consensus Rate", f"{cons_rate:.1%}")
    st.markdown("KPI cards compare current vol to each tier.")

    fig=go.Figure(); fig.add_trace(go.Scatter(x=dfc.index,y=dfc['Vol'], name='Vol'))
    if 'Warning (90%)' in tiers:
        fig.add_trace(go.Scatter(x=dfc.index,y=dfc['Thr_Warning'],
                                 name='Warning', line=dict(dash='dash')))
    if 'Alert (95%)' in tiers:
        fig.add_trace(go.Scatter(x=dfc.index,y=dfc['Thr_Alert'],
                                 name='Alert', line=dict(dash='dot')))
    if 'Critical (EVT)' in tiers:
        fig.add_trace(go.Scatter(x=dfc.index,y=dfc['Thr_Critical'],
                                 name='Critical', line=dict(dash='longdash')))
    fig.update_layout(
        title="Vol vs. Multiâ€Tier Thresholds",
        xaxis=dict(rangeslider=dict(visible=True)),
        yaxis_title="Daily Volatility", height=450
    )
    st.plotly_chart(fig, use_container_width=True)
    breach={'Warning':(dfc['Vol']>dfc['Thr_Warning']).mean(),
            'Alert':(dfc['Vol']>dfc['Thr_Alert']).mean(),
            'Critical':(dfc['Vol']>dfc['Thr_Critical']).mean()}
    st.bar_chart(pd.Series(breach,name='Breach Rate'))

# Base regimes
with tabs[2]:
    st.header(f"{base_cc} Regime Shifts")
    fig_b=px.line(df_base, x='Date',y='Vol',color='RegLabel')
    for d in df_base.loc[chg_b,'Date']:
        fig_b.add_vline(x=d, line_dash='dash', line_color='red', opacity=0.6)
    fig_b.update_layout(title=f"{base_cc} Volatility by Regime")
    st.plotly_chart(fig_b, use_container_width=True)

# Quote regimes
with tabs[3]:
    st.header(f"{quote_cc} Regime Shifts")
    fig_q=px.line(df_quote, x='Date',y='Vol',color='RegLabel')
    for d in df_quote.loc[chg_q,'Date']:
        fig_q.add_vline(x=d, line_dash='dash', line_color='green', opacity=0.6)
    fig_q.update_layout(title=f"{quote_cc} Volatility by Regime")
    st.plotly_chart(fig_q, use_container_width=True)

# Cross regimes
with tabs[4]:
    st.header(f"{base_cc}/{quote_cc} Cross Regime Shifts")
    fig_x=px.line(df_cross, x='Date',y='Vol',color='RegLabel')
    for d in df_cross.loc[chg_x,'Date']:
        fig_x.add_vline(x=d, line_dash='dash', line_color='black', opacity=0.6)
    for d in df_base.loc[chg_b & df_base.Date.isin(df_cross.Date),'Date']:
        fig_x.add_vline(x=d, line_dash='dot', line_color='red', opacity=0.4)
    for d in df_quote.loc[chg_q & df_quote.Date.isin(df_cross.Date),'Date']:
        fig_x.add_vline(x=d, line_dash='dot', line_color='green', opacity=0.4)
    fig_x.add_trace(go.Scatter(x=[None],y=[None],
        mode='lines', line=dict(color='red',dash='dot'),
        name=f"{base_cc} Change"))
    fig_x.add_trace(go.Scatter(x=[None],y=[None],
        mode='lines', line=dict(color='green',dash='dot'),
        name=f"{quote_cc} Change"))
    fig_x.update_layout(title=f"{base_cc}/{quote_cc} Cross by Regime")
    st.plotly_chart(fig_x, use_container_width=True)

# Shock Simulation & Recalibration
with tabs[5]:
    st.header("ðŸš€ Shock Simulation & Recalibration")
    snap = st.date_input("Snapshot Date",
                         value=datetime.date(2024,10,14),
                         min_value=dfc.index.min().date(),
                         max_value=dfc.index.max().date())
    hist = dfc[dfc.index <= pd.to_datetime(snap)]
    hist_lr = cross_lr.loc[:pd.to_datetime(snap)]

    # re-detect & smooth regimes on hist
    raw_h,_,_ = detect_regimes(hist['Vol'], n_states)
    states_h  = smooth_regimes(raw_h,5)
    hist2     = hist.assign(Regime=states_h)

    # calibrate on history
    cp = calibrate_regime(
        hist2['Vol'], hist_lr.values,
        target_rate, roll_windows, roll_qs, evt_tails
    )
    dyn_alert = hist2['Vol'].rolling(cp['window']).quantile(cp['quantile']).iat[-1]
    dyn_evt   = garch_evt(hist_lr.values, cp['tail'])

    cols = st.columns(3)
    cols[0].metric("Manual Thr (static)", f"{man_thr:.4f}")
    cols[1].metric("Dynamic Alert Thr",    f"{dyn_alert:.4f}")
    cols[2].metric("Dynamic EVT Thr",      f"{dyn_evt:.4f}")

    st.markdown(f"""
    - **Snapshot**: {snap} (last B-day before shock).  
    - **Manual threshold** remains **{man_thr:.4f}** (unchanged).  
    - **Dynamic Alert**: rollingâ€quantile(95%) over window {cp['window']} â†’ **{dyn_alert:.4f}**.  
    - **Dynamic EVT**: tail {cp['tail']:.3f} â†’ **{dyn_evt:.4f}**.  

    _Manual static thresholds cannot adapt to new market conditions, whereas our hybrid approach recalibrates instantly._  
    """)
